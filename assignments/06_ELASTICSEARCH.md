# 6. Zadanie: Elastic Search

**Timotej Za≈•ko**

## Zadanie: Pr√°ca s indexom a dokumentami v Elasticsearch

1. Rozbehajte si 3 in≈°tancie Elasticsearch-u
2. Vytvorte index pre Tweety, ktor√Ω bude ma≈• ‚Äúoptim√°lny‚Äú poƒçet shardov a repl√≠k pre 3 nody
(aby tam bola distrib√∫cia dotazov vo vyhƒæad√°van√≠, aj distrib√∫cia ulo≈æen√Ωch d√°t)
3. Vytvorte mapping pre normalizovan√© d√°ta z Postgresu - Tweet mus√≠ obsahova≈• √∫daje rovnak√© ako m√°te u≈æ ulo≈æen√© v PostgreSQL. Dbajte na to, aby ste vytvorili polia v spr√°vnom d√°tovom type (polia ktor√© m√° zmysel analyzova≈• analyzujte spr√°vne, tie ktor√© nem√°, aby neboli zbytoƒçne analyzovan√© (keyword analyzer)) tak aby index nebol zbytoƒçne veƒæk√Ω. Mapovanie mus√≠ by≈• striktn√©.
4. Vytvorte bulk import pre va≈°e normalizovan√© Tweety.
5. Importujete d√°ta do Elasticsearchu
6. Experimentujte s n√≥dami, a zistite koƒæko n√≥dov mus√≠ be≈æa≈• (a ktor√©) aby v√°m Elasticsearch vedel prid√°va≈• dokumenty, maza≈• dokumenty, prezera≈• dokumenty a vyhƒæad√°va≈• nad nimi?
7. Upravujte poƒçet retweetov pre vami vybran√Ω tweet pomocou va≈°eho jednoduch√©ho scriptu (v r√°mci Elasticsearchu) a sledujte ako sa men√≠ _seq_no a_primary_term pri tom ako zab√≠jate a sp√∫≈°≈•ate n√≥dy.

### Hodnotenie

Zadanie ƒç.1 - hodnotenie - dokopy 7,5 boda rozdelen√© percentu√°lne:

- 2 - preƒço ste vytvorili index tak ako ste vytvorili? / 10%
- 3 - ako ste vytvorili mapovanie? / 25%
- 4 - naindexovali ste spr√°vny poƒçet dokumentov (buƒè va≈°e ƒç√≠slo z PostgreSQL, alebo spr√°vny
poƒçet)? / 25%
- 5 - nap√≠sali ste skript tak aby d√°val zmysel / 15%
- 6 + 7 nap√≠≈°te v skratke ak√© pr√≠pady ste si definovali a preƒço. Pop√≠sali ste v√Ωstupy
zmysluplne? Tj. o≈•ukali ste si ako to funguje? / 25%

## Odpovede

### 1. Rozbehajte si 3 in≈°tancie Elasticsearch-u

Rozbehal som, pou≈æil som svoj docker-compose script z [elastic/docker-compose.yml](./../elastic/docker-compose.yml). 

![](./images/020.png)

N√°sledne som spravil e≈°te get request na n√≥dy, aby som overil, ƒçi elastic naozaj be≈æ√≠ a be≈æ√≠ na spr√°vnom porte.

**GET:** `http://localhost:9200/_cat/nodes`

Response:
```
172.19.0.3 45 84 48 1.84 3.31 1.70 cdhilmrstw - es01
172.19.0.4 45 84 48 1.84 3.31 1.70 cdhilmrstw - es02
172.19.0.2 48 84 48 1.84 3.31 1.70 cdhilmrstw * es03s
```

### 2. Vytvorte index pre Tweety, ktor√Ω bude ma≈• ‚Äúoptim√°lny‚Äú poƒçet shardov a repl√≠k pre 3 nody

Zvolil som 3 shardy a 2 repliky. Preƒço?

Nav≈°t√≠vil som preto dokument√°ciu elastic-u [https://www.elastic.co/blog/how-many-shards-should-i-have-in-my-elasticsearch-cluster](https://www.elastic.co/blog/how-many-shards-should-i-have-in-my-elasticsearch-cluster).
A zistil som nasledovn√© (kƒæ√∫ƒçov√© ƒçasti textu som zv√Ωraznil):

> TIP: The number of shards you can hold on a node will be proportional to the amount of heap you have available, but there is no fixed limit enforced by Elasticsearch. __A good rule-of-thumb is to ensure you keep the number of shards per node below 20 per GB heap it has configured.__ A node with a 30GB heap should therefore have a maximum of 600 shards, but the further below this limit you can keep it the better. This will generally help the cluster stay in good health.

M√¥jmu dockeru som nastavil maxim√°lnu pam√§≈• 6GB, tj. ka≈æd√Ω node m√° k dispoz√≠cii v priemere 2GB pam√§te.
Maxim√°lne by som mal ma≈• 40 shardov pre ka≈æd√Ω node, tj. dokopy a≈æ 120. O minim√°lnom poƒçte sa nehovor√≠ niƒç.
Ale keƒè≈æe m√°m 3 nody, mal by som ma≈• minim√°lne tri shardy (kv√¥li paraleln√©mu spracovaniu).

> TIP: Small shards result in small segments, which increases overhead. __Aim to keep the average shard size between at least a few GB and a few tens of GB__. For use-cases with time-based data, it is common to see shards between 20GB and 40GB in size.

≈§a≈æko odhadn√∫≈• koƒæko bud√∫ d√°ta v elasticu zabera≈• miesta na disku. Sk√∫sim to odhadn√∫≈•. Surov√© d√°ta (`.jsonl.gz`) maj√∫ okolo 5GB.
Po rozbalen√≠ jedn√©ho s√∫boru (`.gz`), ktor√Ω m√° 120MB z√≠skam s√∫bor s veƒækos≈•ou okolo 900MB, ƒço je pribli≈æne 7x viac. M√¥≈æeme teda predpoklada≈•, ≈æe v≈°etky surov√© d√°ta maj√∫ okolo 35GB.
Ale neimportujem v≈°etky atrib√∫ty, len niektor√©, ƒço odhadujem na 1/2 (kv√¥li atrib√∫tu ako je description) v≈°etk√Ωch d√°t. Tj. odhadom m√°m okolo 17GB surov√Ωch d√°t.

Mal by som sa teda pohybova≈• v rozmedz√≠ od 3 do 120 shardov, keƒè≈æe moj√≠m odhadom m√°m tak 17GB d√°t (a mo≈æno sa m√Ωlim a m√°m ich menej), mysl√≠m si, ≈æe 3 shardy bud√∫ tak akur√°t, tj. cca 5GB per shard. Tj. som niekde medzi "at least few GB" a "tens of GB".

Zvolil som 2 repliky, repliky sa pou≈æ√≠vaj√∫ v pr√≠pade ak by primary shard bol po≈°koden√Ω, ƒço sa m√¥≈æe sta≈•. 1 replika je by default (tj. shard + jeho replika). 
2 repliky pova≈æujem za tak√∫ istotu, ale nemysl√≠m si, ≈æe v√¥bec nejak√∫ budem potrebova≈• (≈æe by sa mi poƒças zadania po≈°kodil nejak√Ω shard, nerob√≠m toƒæko requestov).

Nastav√≠m teda 3 shardy a 2 repliky.

**PUT:** `http://localhost:9200/tweets`

Body:
```json
{
  "settings": {
    "number_of_shards": 3,
    "number_of_replicas": 2
  }
}
```

**GET:** `http://localhost:9200/_cat/shards`

Response:
```
tweets 2 r STARTED 2325451 1.3gb 172.19.0.2 es03
tweets 2 r STARTED 2325451 1.3gb 172.19.0.4 es02
tweets 2 p STARTED 2325451 1.3gb 172.19.0.3 es01
tweets 1 r STARTED 2325760 1.3gb 172.19.0.2 es03
tweets 1 p STARTED 2325760 1.3gb 172.19.0.4 es02
tweets 1 r STARTED 2325760 1.3gb 172.19.0.3 es01
tweets 0 p STARTED 2328711 1.3gb 172.19.0.2 es03
tweets 0 r STARTED 2328711 1.4gb 172.19.0.4 es02
tweets 0 r STARTED 2328711 1.3gb 172.19.0.3 es01
```
    
### 3. Vytvorte mapping pre normalizovan√© d√°ta z Postgresu - Tweet mus√≠ obsahova≈• √∫daje rovnak√© ako m√°te u≈æ ulo≈æen√© v PostgreSQL. Dbajte na to, aby ste vytvorili polia v spr√°vnom d√°tovom type (polia ktor√© m√° zmysel analyzova≈• analyzujte spr√°vne, tie ktor√© nem√°, aby neboli zbytoƒçne analyzovan√© (keyword analyzer)) tak aby index nebol zbytoƒçne veƒæk√Ω. Mapovanie mus√≠ by≈• striktn√©.

Vytvoril som nasledovn√© mapovanie. Pre location som pou≈æil typ `geo_point`, pre happened_at `date` a `keyword` som pou≈æil iba pre hashtagy a parent_id, keƒè≈æe to v dokument√°cii odpor√∫ƒçali pre atrib√∫ty tak√©hoto typu _"which is used for structured content such as __IDs__, email addresses, hostnames, status codes, zip codes, or __tags__."_.
Pre textov√© polia som pou≈æil typ `text` a pre ƒç√≠seln√© som pou≈æil typ `integer`. 

**PUT:** `http://localhost:9200/tweets/_mapping`

Body:
```json
{
  "dynamic": "strict",
  "properties": {
    "content": {
      "type": "text"
    },
    "location": {
      "type": "geo_point"
    },
    "retweet_count": {
      "type": "integer"
    },
    "favorite_count": {
      "type": "integer"
    },
    "happened_at": {
      "type": "date"
    },
    "author": {
      "properties": {
        "id": {
          "type": "keyword"
        },
        "screen_name": {
          "type": "text"
        },
        "name": {
          "type": "text"
        },
        "description": {
          "type": "text"
        },
        "followers_count": {
          "type": "integer"
        },
        "friends_count": {
          "type": "integer"
        },
        "statuses_count": {
          "type": "integer"
        }
      }
    },
    "country": {
      "properties": {
        "code": {
          "type": "keyword"
        },
        "name": {
          "type": "text"
        }
      }
    },
    "hashtags": {
      "type": "keyword"
    },
    "mentions": {
      "properties": {
        "id": {
          "type": "long"
        },
        "screen_name": {
          "type": "text"
        },
        "name": {
          "type": "text"
        }
      }
    },
    "parent_id": {
      "type": "keyword"
    }
  }
}
```

Response:
```json
{
    "acknowledged": true
}
```

### 4. Vytvorte bulk import pre va≈°e normalizovan√© Tweety.

Bulk import sa sp√∫≈°≈•a pomocou `make to-elastic`. Hlavn√Ω zdrojov√Ω s√∫bor sa nach√°dza v [cmd/toelastic/main.go](../cmd/toelastic/main.go).
Import rob√≠m v paraleln√Ωch coroutin√°ch v bulkoch po 2500 tweetov. Na synchroniz√°ciu corout√≠n pou≈æ√≠vam semafor.

### 5. Importujete d√°ta do Elasticsearchu

D√°ta som naimportoval, takto vyzer√° poƒçet tweetov.

**GET:** `http://localhost:9200/tweets/_count`

Response:
```json
{
    "count": 6979922,
    "_shards": {
        "total": 3,
        "successful": 3,
        "skipped": 0,
        "failed": 0
    }
}
```

### 6. Experimentujte s n√≥dami, a zistite koƒæko n√≥dov mus√≠ be≈æa≈• (a ktor√©) aby v√°m Elasticsearch vedel prid√°va≈• dokumenty, maza≈• dokumenty, prezera≈• dokumenty a vyhƒæad√°va≈• nad nimi?

Pomocou nasledovn√Ωch requestov som overoval, ƒçi funguje prid√°vanie, vyhƒæad√°vanie, mazanie a prezeranie.

Prid√°vanie - **PUT:** `http://localhost:9200/tweets/_doc/1289435277660844032`

```json
{
    "content": "RT @TechnicalGuruji: Hello guys...Giving away these Airpods Pro to you...\nStep 1 - Follow @TechnicalGuruji...\nStep 2 - Retweet this tweet..‚Ä¶",
    "location": null,
    "retweet_count": 34976,
    "favorite_count": 0,
    "happened_at": 1596260301,
    "author": {
        "id": 763629964763631616,
        "screen_name": "Meashishpatel",
        "name": "ashish patel",
        "description": "INDIANüáÆüá≥üáÆüá≥üáÆüá≥üáÆüá≥ ||Student||MBA||Dreamer||2021 IAS Officer||Fan Of M.S.Dhoni ||Marval Fan ||Reader||Cheerful Mood|| The Man with Simplicity|| Beardboy ||",
        "followers_count": 348,
        "friends_count": 231,
        "statuses_count": 37
    },
    "country": null,
    "hashtags": null,
    "mentions": [
        {
            "id": 3992637442,
            "screen_name": "TechnicalGuruji",
            "name": "Gaurav Chaudhary"
        },
        {
            "id": 3992637442,
            "screen_name": "TechnicalGuruji",
            "name": "Gaurav Chaudhary"
        }
    ],
    "parent_id": "1289181743359164418"
}
```

Vyhƒæad√°vanie - **POST:** `http://localhost:9200/tweets/_search`
Body:
```json
{
   "size": 10,
   "query": {
      "match_all": {}
   }
}
```
Mazanie - **DELETE:** `http://localhost:9200/tweets/_doc/1289435277660844032`

Prezeranie - **GET:** `http://localhost:9200/tweets/_doc/1289435277660844032`


N√°sledne som experimentoval a vyp√≠nal som n√≥dy. Sk√∫≈°al som v≈°etky kombin√°cie zapnut√Ωch n√≥dov: `es0 + es1 + es2`; `es0 + es1`; `es0 + es2`; `es1 + es2`, `es0`, `es1`, `es2`, priƒçom som zistil, nasledovn√©:

* Vyhƒæad√°vanie a prezeranie fungovalo v≈ædy, pokiaƒæ bol funkƒçn√Ω aspo≈à jeden node (a bol funkƒçn√Ω tak√Ω node, ktor√Ω poƒç√∫val z vonka na porte 9200, tj. mohli sme tieto pr√≠kazy vykon√°va≈•)
* Mazanie a prid√°vanie fungovalo iba v pr√≠pade, ≈æe ≈æije master node (a ≈æije node, ktor√Ω poƒç√∫va na porte 9200, tj. m√¥≈æeme vykon√°va≈• pr√≠kazy, master t√Ωmto n√≥dom mohola ale aj nemusel by≈•)
* Nemohol som robi≈• pr√≠kazy - HTTP requesty pokiaƒæ bol vypnut√Ω node, ktor√Ω, ako jedin√Ω poƒç√∫val na porte 9200

Keƒè som mal len jeden ≈æij√∫ci node (nie master), mazanie a prid√°vanie odpovedalo nasledovne.                              

```json
{
    "error": {
        "root_cause": [
            {
                "type": "cluster_block_exception",
                "reason": "blocked by: [SERVICE_UNAVAILABLE/2/no master];"
            }
        ],
        "type": "cluster_block_exception",
        "reason": "blocked by: [SERVICE_UNAVAILABLE/2/no master];"
    },
    "status": 503
}
```

Master node som zistil pomocou nasledovn√©ho pr√≠kazu - **GET** `http://localhost:9200/_cat/master`.  

### 7. Upravujte poƒçet retweetov pre vami vybran√Ω tweet pomocou va≈°eho jednoduch√©ho scriptu (v r√°mci Elasticsearchu) a sledujte, ako sa men√≠ seq_no a primary_term pri tom, ako zab√≠jate a sp√∫≈°≈•ate n√≥dy.

Vybral som si tweet s `id` = `1289435277660844032`.

Vytvoril som nasledovn√Ω script, ktor√Ωm som zvy≈°oval retweet_count.

**POST:** `http://localhost:9200/tweets/_update/1289435277660844032`

Body:
```json
{
    "script": "ctx._source.retweet_count += 1"
}
```

Po vykon√°van√≠ scriptu sa postupne zvy≈°oval `retweet_count` a aj `seq_no`. Podƒæa dokument√°cie toto ƒç√≠slo znaƒç√≠ ƒç√≠slo zmeny na index a pou≈æ√≠va sa pri konfliktoch zmien nad dokumentom.
To pom√°ha tomu aby sa nestalo, ≈æe nejak√° nov≈°ia zmena (vy≈°≈°ie `seq_no`) je prep√≠san√° nejakou star≈°ou zmenou (ni≈æ≈°ie `seq_no`)

ƒå√≠slo `primary_term` sa mi zmenilo po vypnut√≠ a zapnut√≠ niektor√Ωch nodov. 
Pri vyp√≠nan√≠ a zap√≠nan√≠ n√≥dov sa ƒçislo `seq_no` st√°le zvy≈°ovalo. 